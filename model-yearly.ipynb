{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import BallTree as BallTree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath = xr.open_dataset(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\ERA5_metOcean_bathy.nc')\n",
    "depthNS = 20\n",
    "shp_coast2 = pd.read_excel(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\Continental shapefile coordinates2.xlsx')\n",
    "ERA5_on_coast = pd.read_excel(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\ERA5_locs_on_coast_fin.xlsx')\n",
    "ERA5_around_coast = pd.read_excel(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\ERA5_coordinates_around_coast_fin.xlsx')\n",
    "X1 = ERA5_on_coast.iloc[:,0]; Y1 = ERA5_on_coast.iloc[:,1]\n",
    "X2 = ERA5_around_coast.iloc[:,0]; Y2 = ERA5_around_coast.iloc[:,1]\n",
    "lfhs20 = pd.read_excel(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\lf_waveheight_lookuptable_d20.xlsx',header=None)\n",
    "lftm20 = pd.read_excel(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\lf_waveperiod_lookuptable_d20.xlsx',header=None)\n",
    "pi = math.pi\n",
    "grav = 9.81\n",
    "seasons = np.array(['DJF', 'MAM', 'JJA', 'SON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['lon', 'lat', 'depth0','shoreN','wind95_1979','wind95_1980','wind95_1981','wind95_1982','wind95_1983','wind95_1984','wind95_1985','wind95_1986','wind95_1987','wind95_1988','wind95_1989','wind95_1990','wind95_1991','wind95_1992','wind95_1993','wind95_1994','wind95_1995','wind95_1996','wind95_1997','wind95_1998','wind95_1999','wind95_2000','wind95_2001','wind95_2002','wind95_2003','wind95_2004','wind95_2005','wind95_2006','wind95_2007','wind95_2008','wind95_2009','wind95_2010','wind95_2011','wind95_2012','wind95_2013','wind95_2014','wind95_2015','wind95_2016','wind95_2017','wind95_2018','swh95_1979','swh95_1980','swh95_1981','swh95_1982','swh95_1983','swh95_1984','swh95_1985','swh95_1986','swh95_1987','swh95_1988','swh95_1989','swh95_1990','swh95_1991','swh95_1992','swh95_1993','swh95_1994','swh95_1995','swh95_1996','swh95_1997','swh95_1998','swh95_1999','swh95_2000','swh95_2001','swh95_2002','swh95_2003','swh95_2004','swh95_2005','swh95_2006','swh95_2007','swh95_2008','swh95_2009','swh95_2010','swh95_2011','swh95_2012','swh95_2013','swh95_2014','swh95_2015','swh95_2016','swh95_2017','swh95_2018','ig95_1979','ig95_1980','ig95_1981','ig95_1982','ig95_1983','ig95_1984','ig95_1985','ig95_1986','ig95_1987','ig95_1988','ig95_1989','ig95_1990','ig95_1991','ig95_1992','ig95_1993','ig95_1994','ig95_1995','ig95_1996','ig95_1997','ig95_1998','ig95_1999','ig95_2000','ig95_2001','ig95_2002','ig95_2003','ig95_2004','ig95_2005','ig95_2006','ig95_2007','ig95_2008','ig95_2009','ig95_2010','ig95_2011','ig95_2012','ig95_2013','ig95_2014','ig95_2015','ig95_2016','ig95_2017','ig95_2018','wavePo_1979','wavePo_1980','wavePo_1981','wavePo_1982','wavePo_1983','wavePo_1984','wavePo_1985','wavePo_1986','wavePo_1987','wavePo_1988','wavePo_1989','wavePo_1990','wavePo_1991','wavePo_1992','wavePo_1993','wavePo_1994','wavePo_1995','wavePo_1996','wavePo_1997','wavePo_1998','wavePo_1999','wavePo_2000','wavePo_2001','wavePo_2002','wavePo_2003','wavePo_2004','wavePo_2005','wavePo_2006','wavePo_2007','wavePo_2008','wavePo_2009','wavePo_2010','wavePo_2011','wavePo_2012','wavePo_2013','wavePo_2014','wavePo_2015','wavePo_2016','wavePo_2017','wavePo_2018','frequency_1979','frequency_1980','frequency_1981','frequency_1982','frequency_1983','frequency_1984','frequency_1985','frequency_1986','frequency_1987','frequency_1988','frequency_1989','frequency_1990','frequency_1991','frequency_1992','frequency_1993','frequency_1994','frequency_1995','frequency_1996','frequency_1997','frequency_1998','frequency_1999','frequency_2000','frequency_2001','frequency_2002','frequency_2003','frequency_2004','frequency_2005','frequency_2006','frequency_2007','frequency_2008','frequency_2009','frequency_2010','frequency_2011','frequency_2012','frequency_2013','frequency_2014','frequency_2015','frequency_2016','frequency_2017','frequency_2018','duration_1979','duration_1980','duration_1981','duration_1982','duration_1983','duration_1984','duration_1985','duration_1986','duration_1987','duration_1988','duration_1989','duration_1990','duration_1991','duration_1992','duration_1993','duration_1994','duration_1995','duration_1996','duration_1997','duration_1998','duration_1999','duration_2000','duration_2001','duration_2002','duration_2003','duration_2004','duration_2005','duration_2006','duration_2007','duration_2008','duration_2009','duration_2010','duration_2011','duration_2012','duration_2013','duration_2014','duration_2015','duration_2016','duration_2017','duration_2018','operability_1979','operability_1980','operability_1981','operability_1982','operability_1983','operability_1984','operability_1985','operability_1986','operability_1987','operability_1988','operability_1989','operability_1990','operability_1991','operability_1992','operability_1993','operability_1994','operability_1995','operability_1996','operability_1997','operability_1998','operability_1999','operability_2000','operability_2001','operability_2002','operability_2003','operability_2004','operability_2005','operability_2006','operability_2007','operability_2008','operability_2009','operability_2010','operability_2011','operability_2012','operability_2013','operability_2014','operability_2015','operability_2016','operability_2017','operability_2018']\n",
    "df = pd.DataFrame(columns = cols, index=range(0,4560))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THRESHOLDS\n",
    "Twind = 13.8\n",
    "Twave = 2.0\n",
    "Tig = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4560):\n",
    "    print(i)\n",
    "    # LOAD ERA5 DATA\n",
    "    ds = xr.open_dataset(r'c:\\Users\\wiegel\\OneDrive - Stichting Deltares\\Documents\\input\\ERA5_output_world_coast\\Loc%s.nc' % i)\n",
    "    dfx = ds.to_dataframe()\n",
    "    dfx = dfx.dropna()\n",
    "    if dfx.empty: continue\n",
    "    \n",
    "    dfx.loc[:,'year'] = dfx.index.year\n",
    "    df.loc[i,'lon'] = dfx.longitude[0]\n",
    "    df.loc[i,'lat'] = dfx.latitude[0]\n",
    "    \n",
    "    # DEPTH OFFSHORE\n",
    "    depth = bath.sel(latitude=dfx.latitude[0], longitude=dfx.longitude[0], method='nearest')\n",
    "    depth = depth.to_dataframe()\n",
    "    df.loc[i,'depth0'] = depth.wmb[0]\n",
    "    if np.isnan(df.loc[i].depth0) or df.loc[i].depth0 <= depthNS: df.loc[i,'depth0'] = depthNS\n",
    "     \n",
    "    # SHORENORMAL ORIENTATION\n",
    "    F = np.array([df.loc[i].lon,df.loc[i].lat]).reshape(1,-1)\n",
    "    x1 = shp_coast2.iloc[:,0].tolist()\n",
    "    y1 = shp_coast2.iloc[:,1].tolist()\n",
    "    X = np.column_stack((x1,y1))\n",
    "    tree = BallTree(X, leaf_size=100)             \n",
    "    dist, ind = tree.query(F, k=1)\n",
    "    Cordmin = (X[ind-4]+X[ind-3]+X[ind-2]+X[ind-1])/4\n",
    "    Cordpls = (X[ind+4]+X[ind+3]+X[ind+2]+X[ind+1])/4\n",
    "    coastcoord = (Cordmin+Cordpls)/2\n",
    "    theta = math.atan2((df.loc[i].lon - coastcoord[0,0,0]),(df.loc[i].lat - coastcoord[0,0,1]))\n",
    "    shoreN = (theta*180/(math.pi)) % 360\n",
    "    if np.isnan(shoreN):\n",
    "        theta = math.atan2(X2[i]-X1[i],Y2[i]-Y1[i])\n",
    "        shoreN = (theta*180/(math.pi)) % 360\n",
    "    df.loc[i,'shoreN'] = shoreN\n",
    "    \n",
    "    for l in range(1979,2019):\n",
    "        print(l)\n",
    "        dfx2 = dfx.loc[dfx['year'] == l]\n",
    "        \n",
    "        # WIND\n",
    "        wind = np.sqrt(dfx2.u10**2 + dfx2.v10**2); wind[-1] = 0; wind[0] = 0\n",
    "        dfx2.loc[:,'wind'] = wind\n",
    "        #df.loc[i,'wind50'] = wind.quantile([0.50]).iloc[0]\n",
    "        df.loc[i,'wind95_' + str(l) ] = wind.quantile([0.95]).iloc[0]\n",
    "        #df.loc[i,'windAv'] = np.count_nonzero(wind < Twind)/len(wind)*100\n",
    "        wind[wind == 13.8]=13.800001\n",
    "        idx = np.argwhere(np.diff(np.sign(Twind - wind))).flatten()\n",
    "        Events = idx.reshape(len(idx)//2,2)\n",
    "        if idx.size != 0:\n",
    "            IntervalIndex = np.column_stack((Events[:-1,1],Events[1:,0]))\n",
    "            ShortIntervalIndex = IntervalIndex[Events[1:,0]-Events[:-1,1] <= 4]\n",
    "            for n in range(0,len(ShortIntervalIndex)):\n",
    "                x = np.arange(ShortIntervalIndex[n,0]+1,ShortIntervalIndex[n,1]+1)\n",
    "                wind[x] = Twind\n",
    "            dfx2.loc[:,'wind'] = wind\n",
    "            df.loc[i,'windAvUp'] = np.count_nonzero(wind < Twind)/len(wind)*100\n",
    "        else:\n",
    "            df.loc[i,'windAvUp'] = 100\n",
    "        \n",
    "        # NEARSHORE TRANSLATION\n",
    "        dirWave = dfx2.mwd\n",
    "        waveHeight = dfx2.swh    \n",
    "        wavePeriod = dfx2.mwp\n",
    "        peakPeriod = dfx2.pp1d\n",
    "        dirWave = dirWave * 1.\n",
    "        waveHeight = waveHeight.astype('float')\n",
    "        wavePeriod = wavePeriod * 1.\n",
    "        depthOffshore = float(df.loc[i].depth0)\n",
    "        depthNearshore = float(depthNS)\n",
    "        shoreNormal = float(shoreN % 360)\n",
    "        #df.loc[i].tp = np.mean(peakPeriod)\n",
    "    \n",
    "        # WAVE LENGHT/NUMBER (DEEP & NEAR) BASED ON THE WAVE PERIOD WHICH REMAINS CONSTANT\n",
    "        # Calculation based on the Matlab function disper.m and transformed to nearshore\n",
    "    \n",
    "        w2 = (2 * pi / wavePeriod)**2 * depthOffshore / grav\n",
    "        q = w2 / ( (1 - np.exp(-(w2**(5/4))))**(2/5))\n",
    "        for j in range(2):\n",
    "            thq = np.tanh(q)\n",
    "            thq2 = 1 - thq**2\n",
    "            a = (1 - q * thq)*thq2\n",
    "            b = thq + q * thq2\n",
    "            c = q * thq - w2\n",
    "            arg = b**2 - (4*a*c)\n",
    "            arg = (-b + np.sqrt(arg)) / (2 * a)\n",
    "            iq = np.abs(a * c) < (10**-8 * b**2)\n",
    "            arg[iq] = - c[iq] / b[iq]\n",
    "            q = q + arg\n",
    "        k = q / depthOffshore\n",
    "        Ldeep = 2 * pi / k\n",
    "    \n",
    "        # Nearshore depth wave number and wave length calculation via dispersion relation\n",
    "        w3 = (2 * pi / wavePeriod)**2 * depthNearshore / grav\n",
    "        q1 = w3 / (1 - np.exp(-(w3**(5/4))))**(2/5)\n",
    "        for m in range(2):\n",
    "            thq = np.tanh(q1)\n",
    "            thq2 = 1 - thq**2\n",
    "            a = (1 - q1 * thq)*thq2\n",
    "            b = thq + q1 *thq2\n",
    "            c = q1 * thq - w3\n",
    "            arg = b**2 - (4*a*c)\n",
    "            arg = (-b + np.sqrt(arg)) / (2 * a)\n",
    "            iq = np.abs(a * c) < (10**-8 * b**2)\n",
    "            arg[iq] = - c[iq] / b[iq]\n",
    "            q1 = q1 + arg\n",
    "        k1 = q1 / depthNearshore\n",
    "        Lnear = 2 * pi / k1\n",
    "  \n",
    "        # Calculate the waveVelocity (deep and near)\n",
    "        Cdeep = ((grav/k) * np.tanh(k * depthOffshore))**0.5\n",
    "        Cnear = ((grav/k1) * np.tanh(k1 * depthNearshore))**0.5\n",
    "    \n",
    "        # Calculate the wave-angle of the point offshore\n",
    "        relDir = (dirWave - shoreNormal + 180.) % 360. - 180.\n",
    "        SinThetadeep = np.sin(relDir * (pi/180.))\n",
    "    \n",
    "        # Calculate the wave-angle of the point near the coast\n",
    "        SinThetanear = (SinThetadeep / Cdeep) * Cnear\n",
    "        relDirnear = np.arcsin(SinThetanear) * (180./pi)\n",
    "    \n",
    "        # Refraction coefficient\n",
    "        Kr = (np.cos(relDir * (pi/180.)) / np.cos(relDirnear * (pi/180.)))**0.5\n",
    "        Kr[(Kr < 0.8)] = 0.8\n",
    "        #df.loc[i].Kr = np.mean(Kr)\n",
    "    \n",
    "        # Calculate group wave velocities\n",
    "        waveNumberdeep = 2*pi / Ldeep\n",
    "        if depthOffshore/Ldeep.any() > 0.5: ndeep = 0.5\n",
    "        else: ndeep = 0.5 * (1 + (2 * waveNumberdeep * depthOffshore) / np.sinh(2 * waveNumberdeep * depthOffshore))\n",
    "        waveVelocitydeep = ( (grav*Ldeep / (2*pi)) * np.tanh(2*pi * depthOffshore / Ldeep) )**0.5\n",
    "        Cgroupdeep = ndeep * waveVelocitydeep\n",
    "        waveNumbernear = 2*pi / Lnear\n",
    "        nnear = 0.5 * (1 + (2 * waveNumbernear * depthNearshore) / np.sinh(2 * waveNumbernear * depthNearshore))\n",
    "        waveVelocitynear = ( (grav*Lnear / (2*pi)) * np.tanh(2*pi * depthNearshore / Lnear) )**0.5\n",
    "        Cgroupnear = nnear * waveVelocitynear\n",
    "    \n",
    "        # Shoaling coefficient:\n",
    "        Ks = (Cgroupdeep / Cgroupnear) ** 0.5\n",
    "        #df.loc[i].Ks = np.mean(Ks)\n",
    "    \n",
    "        # Wave-climate of the near shore\n",
    "        waveHeightnearAlldir = Ks * waveHeight\n",
    "        waveHeightnearAlldir[waveHeightnearAlldir > (depthNearshore*0.73)] = depthNearshore*0.73\n",
    "        dfx2.loc[:,'swh_nr_ad'] = waveHeightnearAlldir\n",
    "        waveHeightnearReldir = Kr * Ks * waveHeight\n",
    "        waveHeightnearReldir[waveHeightnearReldir > (depthNearshore*0.73)] = depthNearshore*0.73\n",
    "        dfx2.loc[:,'swh_nr_rd'] = waveHeightnearReldir\n",
    "        wavePeriodnear = wavePeriod * 1.\n",
    "        #df.loc[i].tm = np.mean(wavePeriodnear)\n",
    "        ixD = ~((-90 < relDir) & (relDir < 90))\n",
    "        waveHeightnearReldir[ixD] = float('NaN')\n",
    "        waveHeightnearReldir[ixD] = float('NaN')\n",
    "        relDirnear[ixD] = relDir[ixD]\n",
    "        #df.loc[i,'swh50'] = waveHeightnearReldir.quantile([0.5]).iloc[0]\n",
    "        df.loc[i,'swh95_' + str(l) ] = waveHeightnearReldir.quantile([0.95]).iloc[0]\n",
    "        waveHeightnearReldir = waveHeightnearReldir.fillna(0)\n",
    "        #df.loc[i,'swhAv'] = np.count_nonzero(waveHeightnearReldir < Twave)/len(waveHeightnearReldir)*100\n",
    "        waveHeightnearReldir[-1] = 0; waveHeightnearReldir[0] = 0\n",
    "        idx = np.argwhere(np.diff(np.sign(Twave - waveHeightnearReldir))).flatten()\n",
    "        Events = idx.reshape(len(idx)//2,2)\n",
    "        if idx.size != 0:\n",
    "            IntervalIndex = np.column_stack((Events[:-1,1],Events[1:,0]))\n",
    "            ShortIntervalIndex = IntervalIndex[Events[1:,0]-Events[:-1,1] <= 4]\n",
    "            for n in range(0,len(ShortIntervalIndex)):\n",
    "                x = np.arange(ShortIntervalIndex[n,0]+1,ShortIntervalIndex[n,1]+1)\n",
    "                waveHeightnearReldir[x] = Twave\n",
    "            dfx2.loc[:,'swh_nr_rd'] = waveHeightnearReldir\n",
    "            df.loc[i,'swhAvUp'] = np.count_nonzero(waveHeightnearReldir < Twave)/len(waveHeightnearReldir)*100\n",
    "        else:\n",
    "            df.loc[i,'swhAvUp'] = 100\n",
    "   \n",
    "        # Infragravity (bound) waves nearshore\n",
    "        idhs = (dfx2.swh_nr_ad * 20).round().astype(int)\n",
    "        idhs[idhs > 249]=249\n",
    "        idtp = (peakPeriod * 10).round().astype(int)\n",
    "        idtp[idtp > 249]=249\n",
    "        lfhs = np.array(lfhs20)\n",
    "        lftm = np.array(lftm20)\n",
    "        lfhs = lfhs[idhs,idtp]\n",
    "        lftm = lftm[idhs,idtp]\n",
    "        lfhs[-1] = 0; lfhs[0] = 0\n",
    "        dfx2.loc[:,'lfhs'] = lfhs\n",
    "        dfx2.loc[:,'lftm'] = lftm\n",
    "        #df.loc[i,'ig50'] = dfx2.lfhs.quantile([0.50]).iloc[0]\n",
    "        df.loc[i,'ig95_' + str(l) ] = dfx2.lfhs.quantile([0.95]).iloc[0]\n",
    "        #df.loc[i,'igAv'] = np.count_nonzero(lfhs < Tig)/len(lfhs)*100\n",
    "        idx = np.argwhere(np.diff(np.sign(Tig - lfhs))).flatten()\n",
    "        Events = idx.reshape(len(idx)//2,2)\n",
    "        if idx.size != 0:\n",
    "            IntervalIndex = np.column_stack((Events[:-1,1],Events[1:,0]))\n",
    "            ShortIntervalIndex = IntervalIndex[Events[1:,0]-Events[:-1,1] <= 4]\n",
    "            for n in range(0,len(ShortIntervalIndex)):\n",
    "                lfhs[np.arange(ShortIntervalIndex[n,0]+1,ShortIntervalIndex[n,1]+1)] = Tig\n",
    "            dfx2.loc[:,'lfhs'] = lfhs\n",
    "            df.loc[i,'igAvUp'] = np.count_nonzero(lfhs < Tig)/len(lfhs)*100\n",
    "        else:\n",
    "            df.loc[i,'igAvUp'] = 100\n",
    "\n",
    "        # Longshore Sediment Transport potential\n",
    "        dfx2.loc[:,'wavePo'] = waveHeightnearAlldir**2.5*np.sin(2*SinThetanear)\n",
    "        df.loc[i,'wavePo_' + str(l) ] = np.sum(np.abs(dfx2.wavePo))/len(waveHeightnearAlldir)\n",
    "\n",
    "        #Calculate the operability\n",
    "        dfy = pd.concat([dfx2.wind >= Twind, dfx2.swh_nr_rd >= Twave, dfx2.lfhs >= Tig], axis=1)\n",
    "        dfz = dfy[dfy.wind | dfy.swh_nr_rd | dfy.lfhs]\n",
    "        df['operability_' + str(l) ].loc[i] = (len(dfy.index) - len(dfz.index))/len(dfy.index)*100\n",
    "\n",
    "        #Calculate the frequency (per year) shut down and restart again limits the uptime\n",
    "        freq = dfy.sum(axis=1); freq[-1] = 0; freq[0] = 0\n",
    "        if np.sum(freq) != 0:\n",
    "            idx2 = np.argwhere(np.diff(freq > 0)).flatten()\n",
    "            df['frequency_' + str(l) ].loc[i] = len(idx2.reshape(len(idx2)//2,2))\n",
    "\n",
    "        #Calculate the duration (per event) short periods could be caught up more quickly\n",
    "            Events2 = idx2.reshape(len(idx2)//2,2)\n",
    "            df['duration_' + str(l) ].loc[i] = np.sum(Events2[:,1]-Events2[:,0])/len(Events2)\n",
    "        else: df['frequency_' + str(l) ].loc[i] = 0; df['duration_' + str(l) ].loc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('output_run3_yearly_4560locs_d20_w138_s_2_i_005.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
